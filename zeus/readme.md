# =<2d vision 설명>=
곡선의 테두리를 인식한 후 이를 약 30등분을 하고, 약 30개의 점을 추출하였다. 그 후, 두개의 점끼리 짝을지어 15개의 점을 최종적으로 생성하였다. 이 점에 놓일 젠가의 각도값을 계산할 때에는 점의 법선벡터를 이용하여 추출하였다. 
2d vision을 통하여 총 15개의 점의 x,y좌표값과 각도값을 서버측으로 데이터 전송을 한다. 
# =<3d vision 설명>=
detectron2 모델을 사용하여 젠가를 학습시켰다. 
젠가의 넓은면과 좁은면, 두가지케이스를 학습시켰다.
이를 통해 카메라로 찍은 이미지상에서 젠가의 유형을 파악하고 그중 인식률이 가장 높은 젠가를 타겟으로 잡는다. 
그 후 해당젠가의 센터포인트를 추출하고 기울어진 각도값을 계산하였다. 또한 센터포인트의 뎁스값을 측정하여 서버측으로 데이터 전송을 하였다. (사실 이부분에서 뎁스가 잘 안나와서 고정값을 사용하였다)
# =<로봇 모션 설명>=
앞서 설명드린 2d vision으로 얻은 데이터와 3d vision으로 얻는 데이터들을 바탕으로 로봇의 x,y,z,rz,ry,rx값을 계산하여 젠가를 픽하고 플레이스하는 모션을 구현하였다. 
# ***
서버 소스 : endtool_multiPick&Place_1025.py
클라이언트 소스 : no_gpu_rec_1027_multiPick_Place 파일(data_test.py가 메인파일임)
